# Concept-RAG Environment Configuration

# ==============================================================================
# OPENROUTER API CONFIGURATION (Required for concept extraction)
# ==============================================================================
# Get your API key at: https://openrouter.ai/keys
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Optional: Override default models for concept extraction
# OPENROUTER_CONCEPT_MODEL=anthropic/claude-sonnet-4.5
# OPENROUTER_SUMMARY_MODEL=x-ai/grok-4-fast
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# ==============================================================================
# EMBEDDING PROVIDER CONFIGURATION (Optional - for production embeddings)
# ==============================================================================
# Choose your embedding provider: simple, openai, openrouter, or huggingface
# Default: simple (no API key required, suitable for development/testing)
# EMBEDDING_PROVIDER=simple

# ------------------------------------------------------------------------------
# OpenAI Embeddings (if using EMBEDDING_PROVIDER=openai)
# ------------------------------------------------------------------------------
# Get your API key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-proj-...
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# OPENAI_BASE_URL=https://api.openai.com/v1

# ------------------------------------------------------------------------------
# OpenRouter Embeddings (if using EMBEDDING_PROVIDER=openrouter)
# ------------------------------------------------------------------------------
# Note: Can reuse the OPENROUTER_API_KEY from above
# OPENROUTER_API_KEY=sk-or-v1-...
# OPENROUTER_EMBEDDING_MODEL=openai/text-embedding-3-small
# OPENROUTER_EMBEDDING_BASE_URL=https://openrouter.ai/api/v1

# ------------------------------------------------------------------------------
# HuggingFace Embeddings (if using EMBEDDING_PROVIDER=huggingface)
# ------------------------------------------------------------------------------
# Option 1: Use HuggingFace API (get key from: https://huggingface.co/settings/tokens)
# HUGGINGFACE_API_KEY=hf_...
# HUGGINGFACE_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Option 2: Use local inference (no API key required, requires @xenova/transformers)
# HUGGINGFACE_USE_LOCAL=true
# HUGGINGFACE_MODEL=Xenova/all-MiniLM-L6-v2

# ==============================================================================
# DATABASE CONFIGURATION (Optional)
# ==============================================================================
# Default: ~/.concept_rag
# Uncomment to use a custom database location
# DATABASE_URL=/custom/path/to/database
# CONCEPT_RAG_DB=/custom/path/to/database

# ==============================================================================
# LOGGING & PERFORMANCE (Optional)
# ==============================================================================
# Logging level (options: debug, info, warn, error)
# LOG_LEVEL=info

# Batch processing configuration
# BATCH_SIZE=10  # Number of documents to process in parallel during seeding
# MAX_TOKENS=100000  # Maximum tokens per document for concept extraction
